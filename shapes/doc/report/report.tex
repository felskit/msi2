\documentclass[11pt,a4paper]{article}
\usepackage{fullpage}
\usepackage[T1]{fontenc} 
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{float}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage[table,dvipsnames]{xcolor}
\usepackage[hidelinks]{hyperref}
\usepackage[polish]{babel}
\usepackage{menukeys}

\def\arraystretch{1.5}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\renewcommand{\thesection}{\arabic{section}.}
\renewcommand{\thesubsection}{\thesection\arabic{subsection}.}
\renewcommand{\thesubsubsection}{\thesubsection\arabic{subsubsection}.}
\setlength{\parindent}{0cm}
\setlength{\parskip}{2mm}

\begin{document}

\title{Metody sztucznej inteligencji 2 \\
\Large{
    Projekt 2. --- Rozpoznawanie kształtów w czasie rzeczywistym \\
    Raport końcowy
}}
\author{Bartłomiej Dach \and Tymon Felski}
\maketitle

Poniższy dokument zawiera końcowy opis projektu, którego celem jest zaimplementowanie rozwiązania pozwalającego na~detekcję i~rozpoznawanie prostych kształtów na~obrazach za~pomocą metod geometrycznych oraz z~użyciem sieci neuronowych i~porównanie skuteczności oraz~wydajności obu wariantów.

\section{Opis problemu badawczego}

Zagadnienie rozpoznawania obiektów na~obrazach z~użyciem metod sztucznej inteligencji stanowi duży obszar zainteresowań naukowych.
Efektywne rozwiązanie tego zagadnienia pomogłoby usprawnić wiele procesów, dotychczas wymagających ludzkiej kontroli i~interwencji.

W~niniejszym projekcie zbiór rozpoznawanych typów obiektów został zawężony do~czterech rodzajów kształtów geometrycznych: trójkąta, kwadratu, koła i~gwiazdy pięcioramiennej (patrz rys, \ref{fig:shapes}).
Kształty mogą znajdować się w~dowolnej orientacji i~mieć dowolny rozmiar.
Dla~uproszczenia zakładamy również, że kolor rozpoznawanych obiektów jest jednakowy i~znany \emph{a~priori}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{res/img/triangle.png}
    \end{subfigure}
    \begin{subfigure}[t]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{res/img/square.png}
    \end{subfigure}
    \\
    \begin{subfigure}[t]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{res/img/star.png}
    \end{subfigure}
    \begin{subfigure}[t]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{res/img/circle.png}
    \end{subfigure}
    \caption{Przykładowe kształty ze~zbioru treningowego używanego do~treningu i~oceny jakości klasyfikatorów}
    \label{fig:shapes}
\end{figure}

\subsection{Cel badań}

Kształty geometryczne wykazują pewien stopień regularności, co~powoduje, że do~ich rozpoznawania można próbować zastosować algorytmy dokładne.
Przykładem są zaimplementowane w~bibliotece OpenCV \cite{opencv}:
\begin{itemize}
    \item algorytm Suzukiego \cite{suzuki1985} do~wyznaczania konturów na~podstawie obrazów rastrowych,
    \item algorytm Douglasa-Peuckera \cite{douglas1973} do~upraszczania konturów i~redukcji liczby punktów.
\end{itemize}
Dzięki tym dwóm algorytmom można na~podstawie binarnego obrazu wejściowego wyznaczyć kontur kształtu --- łamaną zamkniętą przybliżającą kształt wyznaczony przez piksele kształtu na~tle.

Oprócz metod dokładnych, do~zagadnienia rozpoznawania można również użyć sieci neuronowych, które zamiast wiedzy dokładnej używają przygotowanych zbiorów treningowych oraz metod optymalizacji, aby~dokonać klasyfikacji.
Celem badań jest porównanie wydajności i~skuteczności wybranych metod.

\newpage
\subsection{Wykorzystane techniki}

Do~zaimplementowania klasyfikatorów użyty został język skryptowy \textbf{Python} w~wersji 3.5.2.
Ponadto wykorzystane zostały dodatkowe biblioteki, wymienione w~tabeli~\ref{tbl:libraries}.
Podejście geometryczne opiera~się na~funkcjach udostępnianych przez \textbf{OpenCV}, podczas gdy sieci neuronowe stworzone zostały za~pośrednictwem API dostarczanego przez bibliotekę \textbf{Keras}.

\begin{table}[H]
    \begin{tabularx}{\textwidth}{|c|l|X|l|c|}
        \hline
        \textbf{Nr} & \textbf{Komponent, wersja} & \textbf{Opis} & \textbf{Licencja} & \\
        \hline
        \hline
        1 &
        h5py, 2.7.1 &
        Interfejs dla binarnego formatu danych HDF5, wymagany przez Keras &
        BSD License &
        \cite{h5py} \\
        \hline
        2 &
        Keras, 2.1.4 &
        Biblioteka udostępniająca API do~sieci neuronowych &
        MIT License &
        \cite{keras} \\
        \hline
        3 & 
        Matplotlib, 2.1.0 & 
        Umożliwia tworzenie wykresów &
        Matplotlib License &
        \cite{matplotlib} \\
        \hline
        4 & 
        NumPy, 1.13.3 &
        Używana do~efektywnych obliczeń na~wektorach $n$-wymiarowych &
        BSD License &
        \cite{numpy} \\
        \hline
        5 & 
        OpenCV, 3.3.0 &
        Biblioteka do~obróbki obrazów &
        New BSD License &
        \cite{opencv} \\
        \hline
        6 &
        pandas, 0.21.0 &
        Wspomaga ładowanie danych z~plików CSV oraz~ich analizę &
        BSD License &
        \cite{pandas} \\
        \hline
        7 &
        TensorFlow, 1.8.0 &
        Framework do~uczenia maszynowego używany przez Keras &
        Apache 2.0 &
        \cite{tensorflow} \\
        \hline
    \end{tabularx}
    \caption{Wykorzystane biblioteki wraz z~określeniem licencji}
    \label{tbl:libraries}
\end{table}

\subsubsection{Wycięcie kształtów z~tła}

Ponieważ projekt zakłada, że kolor kształtów jest zadany z~góry, do~ekstrakcji kształtów z~tła wystarczy zastosować operację progowania obrazu.
Pozwala ona na~zamianę obrazu w~kolorze na~obraz binarny.
Progowanie wykonywane jest w~przestrzeni kolorów HSV, która dobrze odwzorowuje podobieństwo odcieni barw; wystarczy zdefiniować przedział dla~parametru H, który określa sąsiedztwo tonalne żądanego koloru.

\newpage
Komponent programu -- nazywany dalej ekstraktorem -- znajdujący figury na~obrazie i~wycinający je z~niego do~późniejszej analizy przez klasyfikatory jest niezależnym modułem. Wykorzystanie go we wszystkich klasyfikatorach pozwala wykluć jego wpływ na~jakość klasyfikacji w~przypadku każdego z klasyfikatorów.

\subsubsection{Klasyfikator geometryczny}

Główną ideą działania klasyfikatora geometrycznego jest dopasowanie łamanej zamkniętej do~rozpoznanego kształtu i~analiza kształtu tej łamanej.

Do~odróżniania kształtów wykorzystywana jest przede wszystkim liczba wierzchołków w~wyznaczonym konturze.
Pozwala ona na~proste odróżnienie trójkątów, czworokątów i~dziesięciokątów od~pozostałych kształtów.
Ponadto, dla~każdego kształtu innego niż trójkąt, stosowane~są odpowiednie heurystyki:

\begin{itemize}
    \item W~przypadku kwadratów, sprawdzana jest proporcja wysokości do~szerokości kształtu (powinna być bliska jedności).
    Ponadto bok kwadratu wyznaczany jest na~podstawie pola i~obwodu figury; jeśli dwie wyznaczone wartości nie są bliskie sobie, kształt jest odrzucany.
    \item Rozpoznawanie gwiazd korzysta z~faktu, że wierzchołki parzyste i~nieparzyste gwiazdy znajdują~się w~innych odległościach od~środka figury.
    Zatem, jeśli odchylenie standardowe odległości od~środka wierzchołków parzystych i nieparzystych jest zbyt duże, figura jest odrzucana.
    \item Dla~kół, podobnie jak dla~kwadratów, promień koła wyznaczany jest dwukrotnie na~podstawie pola i~obwodu figury.
    W~przypadku zbyt dużej różnicy kształt nie jest klasyfikowany.
\end{itemize}

\subsubsection{Klasyfikatory oparte na~sieciach neuronowych}

Klasyfikatory oparte na~sieciach były trenowane na~podstawie zbioru treningowego \cite{shapes}.
Zostały opracowane dwa warianty sieci, operujące na~obrazie wejściowym rozmiarów $64 \times 64$:

\begin{itemize}
    \item W~pierwszym wariancie wejściowy binarny obraz dwuwymiarowy spłaszczany jest do~jednowymiarowego wektora, który przekazywany jest na~wejście sieci.
    Użyta sieć korzysta z~trzech warstw ukrytych z~funkcją aktywacji ReLU (ang. \emph{Rectified Linear Unit}).
    Ponadto, po~każdej warstwie ukrytej dodana jest warstwa \emph{dropout}, zapobiegająca zjawisku \emph{overfitting} \cite{srivastava2014}.

    Warstwa wyjściowa jako funkcji aktywacji używa funkcji \emph{softmax}.
    \item Drugi wariant korzysta z~pojedynczej warstwy konwolucyjnej z~rozmiarem okna $8 \times 8$ oraz warstwy \emph{dropout}.
    Wynik warstwy konwolucyjnej jest spłaszczany i~dostarczany do~warstwy wyjściowej z~funkcją \emph{softmax}, w~celu znormalizowania wartości wyjściowej do~przedziału $[0,1]$.
\end{itemize}

Głównymi dobieranymi parametrami podczas treningu parametrami była liczba epok oraz~tzw. \emph{batch size}.
Eksperymenty, których wyniki widoczne~są na~wykresie \ref{fig:epoch-batch-influence}, pokazują, że~mają one niewielki wpływ na~efektywność sieci.
W~związku z~tym przyjęto wartości:
\begin{itemize}
    \item 50 epok i \emph{batch size} 256 --- dla sieci w~modelu płaskim,
    \item 25 epok i \emph{batch size} 256 --- dla sieci w~modelu konwolucyjnym.
\end{itemize}

Oprócz weryfikacji wpływu parametrów na~efektywność klasyfikatorów zbadany został również wpływ procesów stochastycznych będących częścią treningu, tj.:
\begin{itemize}
    \item losowania początkowych wartości wag i \emph{bias},
    \item losowego działania warstw \emph{dropout},
    \item mieszania kolejności obrazów ze~zbioru testowego.
\end{itemize}
W~tym celu uruchomiono trening w~obu modelach dziesięciokrotnie i~zbadano wartości funkcji straty i~dokładności klasyfikacji.
Wyniki zaprezentowane zostały na~wykresie \ref{fig:nondeterminism}.
Patrząc na~wygląd wykresów, można wywnioskować, że~procesy niedeterministyczne mają mały wpływ na~działanie klasyfikatorów i~ich istnienie można w~dalszych rozważaniach pominąć.

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{res/img/loss_conv.pdf}
    \end{subfigure}
    \qquad
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{res/img/acc_conv.pdf}
    \end{subfigure}
    \\
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{res/img/loss_vec.pdf}
    \end{subfigure}
    \qquad
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{res/img/acc_vec.pdf}
    \end{subfigure}
    \caption{Wykresy przedstawiające wpływ dobieranych parametrów (liczby epok i~\emph{batch size}) na~wartość funkcji straty i~dokładność klasyfikacji.
    Na~wykresie przedstawiona wartość średnia z~trzech osobnych uruchomień dla~każdego zestawu parametrów.
    Niedeterminizm został zminimalizowany poprzez ustalenie ziarna generatora liczb pseudolosowych.}
    \label{fig:epoch-batch-influence}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{res/img/randomness_loss.pdf}
    \end{subfigure}
    \qquad
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{res/img/randomness_accuracy.pdf}
    \end{subfigure}
    \caption{Wykresy pudełkowe przedstawiające wpływ niedeterminizmu w~procesie treningu sieci neuronowych w~obu modelach na~wartości funkcji straty i~dokładność klasyfikacji.}
    \label{fig:nondeterminism}
\end{figure}

\section{Instrukcja użytkowania}

W~skład projektu wchodzą trzy główne skrypty Pythona, odpowiadające kolejno za~trenowanie klasyfikatorów opartych na~sieciach neuronowych i~testowanie działania wszystkich trzech klasyfikatorów na~obrazach statycznych oraz strumieniach wideo z~kamery komputera. 

\subsection{Trenowanie sieci neuronowej}

Do~wykonania treningu sieci neuronowej należy wykorzystać skrypt \verb+train.py+.
Dokonuje on wyznaczenia modelu dla~sieci w~obu wariantach (spłaszczonym i~konwolucyjnym).
Skrypt należy wywołać poleceniem
\begin{verbatim}
$ python train.py -d train-image-directory
                  -t train-size
\end{verbatim}

Skrypt przyjmuje następujące parametry:
\begin{itemize}
    \item \verb+train-image-directory+ oznacza katalog zawierający zbiór treningowy udostępniony w~\cite{shapes}.
    Obrazy w~zbiorze treningowym muszą zawierać czarne kształty na~białym tle.
    \item \verb+train-size+ określa stosunek liczności zbioru treningowego do~całości zbioru w~procesie uczenia sieci.
    Przykładowo, podanie wartości \verb+-t 0.8+ spowoduje, że 80\% obrazów z~określonego folderu zostanie przydzielona do~zbioru treningowego, zaś pozostałe 20\% --- do~zbioru testowego.
    Oczekiwaną wartością parametru jest liczba z~zakresu $[0, 1]$.
\end{itemize}

Wykonanie skryptu rozpocznie proces uczenia sieci, który może potrwać do~kilkunastu minut.
W~wyniku działania skryptu w~bieżącym katalogu zostanie stworzony podkatalog \verb+model+, zawierający dwa pliki:

\begin{itemize}
    \item Plik \verb+shapes_model_1d_vec.h5+ zawiera model dla~sieci neuronowej operującej na~spłaszczonym obrazie wytrenowany przy użyciu 50 epok.
    \item Plik \verb+shapes_model_2d_img.h5+ zawiera model dla~konwolucyjnej sieci neuronowej wytrenowany przy użyciu 25 epok.
\end{itemize}

\subsection{Testy na~obrazach wczytywanych z~pliku}

Klasyfikacji dla~folderu zawierającego obrazy można wykonać za~pomocą skryptu \verb+image_test.py+.
Skrypt ten wczyta wszystkie obrazy (z białymi kształtami na~czarnym tle) znajdujące~się w~danym folderze i~dokona ich zbiorczej identyfikacji.
Do~uruchomienia go należy użyć polecenia
\begin{verbatim}
$ python image_test.py -d test-image-directory
                       -c {geometric,vector-network,convolutional-network}
\end{verbatim}

\begin{itemize}
    \item W~parametrze \verb+-d+ podajemy ścieżkę do~folderu, w~którym znajdują~się obrazy testowe.
    \item Parametr \verb+-c+ służy wyborowi klasyfikatora, który powinien być użyty dla~danych testowych.
    Możliwe opcje to:
    \begin{itemize}
        \item \verb+geometric+ --- używa klasyfikatora geometrycznego,
        \item \verb+vector-network+ --- używa klasyfikatora opartego o~płaską sieć neuronową,
        \item \verb+convolutional-network+ --- używa klasyfikatora opartego o~sieć konwolucyjną.
    \end{itemize}
\end{itemize}

Na~wyjściu program wypisze liczbę rozpoznanych kształtów każdego rodzaju na~wszystkich obrazach znajdujących~się w~wyspecyfikowanym katalogu.

\subsection{Rozpoznawanie kształtów w~czasie rzeczywistym}

Ostatni skrypt, \verb+capture.py+, służy demonstracji działania klasyfikatorów na~strumieniu wideo.
Obraz pobierany jest z~kamerki komputera, jeśli taką posiada.
Skrypt uruchamiamy bez parametrów poleceniem:
\begin{verbatim}
$ python capture.py
\end{verbatim}
Skrypt ma~charakter interaktywnego okna --- za~pomocą klawiszy klawiatury można przełączać~się między klasyfikatorami lub dokonać próby czasowej.
Dokładny opis wszystkich opcji znajduje~się poniżej.

\begin{itemize}
    \item Klawisze numeryczne służą przełączaniu~się między klasyfikatorami, których wyniki wyświetlane~są na~podglądzie.
    \begin{itemize}
        \item Klawisz \keys{1} powoduje przełączenie podglądu na~klasyfikator geometryczny.
        \item Klawisz \keys{2} powoduje przełączenie podglądu na~wektorowy klasyfikator z~siecią neuronową.
        \item Klawisz \keys{3} powoduje przełączenie podglądu na~klasyfikator z~konwolucyjną siecią neuronową.
    \end{itemize}
    \item Za~pomocą skryptu można wykonać próbę czasową wszystkich klasyfikatorów dla~ustalonego rodzaju kształtu.
    Dla~każdego klasyfikatora liczony jest czas poprawnej klasyfikacji oraz liczba klatek, na~której kształt został zidentyfikowany pomyślnie.
    Czas zatrzymywany jest, jeśli klasyfikator przez dłużej niż~8~klatek podejmował próbę rozpoznania kształtu i rozpoznawał inny kształt niż był ustawiony obecnie oczekiwany lub gdy stwierdził, że wykryty obszar nie zawiera żadnego ze znanych mu kształtów. Zliczanie poprawnych klatek w~każdym klasyfikatorze nie zatrzymuje się wraz z~zatrzymaniem jego czasomierza. Analogicznie, ogólny czasomierz zatrzyma się tylko, jeżeli zatrzymana zostanie cała rozpoczęta próba czasowa.
    \begin{itemize}
        \item Klawisze \keys{Z}, \keys{X}, \keys{C}, \keys{V} pozwalają zmienić rodzaj kształtu.
        \begin{itemize}
            \item Wciśnięcie klawisza \keys{Z} spowoduje, że oczekiwanym kształtem będzie kwadrat.
            \item Wciśnięcie klawisza \keys{X} spowoduje, że oczekiwanym kształtem będzie gwiazda.
            \item Wciśnięcie klawisza \keys{C} spowoduje, że oczekiwanym kształtem będzie koło.
            \item Wciśnięcie klawisza \keys{V} spowoduje, że oczekiwanym kształtem będzie trójkąt.
        \end{itemize}
        \item Klawisz \keys{A} powoduje rozpoczęcie próby czasowej.
        \item Klawisz \keys{S} powoduje zatrzymanie rozpoczętej próby czasowej.
        \item Klawisz \keys{R} powoduje zrestartowanie próby czasowej.
    \end{itemize}
    Podczas trwania próby można zarówno zmieniać docelowy typ rozpoznawanego kształtu, jak i~przełączać podgląd wyników klasyfikatora między dostępnymi opcjami.
    \item Klawisz \keys{H} powoduje wyświetlenie pomocy na~ekranie.
    \item Klawisz \keys{D} powoduje włączenie trybu \emph{debug}.
    W~tym trybie w~osobnym oknie na~ekranie wyświetlane~są rozpoznawane po~progowaniu kontury, a na~konsoli wyświetlane są: średni, minimalny i maksymalny czas działania poszczególnych klasyfikatorów.
    \item Klawisz \keys{Q} powoduje zakończenie działania skryptu.
\end{itemize}

\section{Wyniki eksperymentalne}

W~celu oceny zaimplementowanych klasyfikatorów wykonane zostało kilka eksperymentów, których celem było zbadanie ich efektywności i~wydajności.
Niniejszy rozdział zawiera opis wykonanych testów oraz~przedstawia uzyskane wyniki.

\subsection{Kryteria oceny klasyfikatorów}

Ocenie zdecydowano się poddać kilka kryteriów. Wyniki klasyfikacji postanowiono zbadać poprzez wyznaczenie dokładności \emph{(ang. accuracy)}, która jest jedną z miar oceny jakości klasyfikacji. Wydajność klasyfikatorów zweryfikowano mierząc czas wywołań klasyfikacji dla każdego z~nich. Ponadto klasyfikatory poddano próbie o~charakterze empirycznym, polegającej na~teście w~czasie rzeczywistym. 

\subsubsection{Dokładność}

Dokładność jest najbardziej intuicyjnym pojęciem pozwalającym na zmierzenie szeroko rozumianej skuteczności klasyfikatora. Dokładność jest bowiem stosunkiem liczby poprawnych klasyfikacji do~ogólnej liczby podjętych prób.

Dla każdego obrazu ze zbioru \cite{shapes} uruchomiono klasyfikację kształtu przy pomocy klasyfikatora geometrycznego i każdej z sieci neuronowych. Następnie zgodnie z definicją dokładności zliczono poprawne wyniki i wyznaczono szukany współczynnik.

W przypadku rozpatrywanych sieci neuronowych dokładność jest dodatkowo jedną z~miar wypisywanych na ekran w trybie \emph{verbose} podczas treningu. Podczas trenowania zbiór danych wejściowych dzielony jest na dwa zbiory --- co piąty element dodawany jest do~zbioru testowego. Zbiór treningowy zawiera wobec tego 80\% obrazów, a po każdej epoce następuje walidacja obecnego stanu sieci przy pomocy pozostałych 20\% obrazów. Na samym końcu treningu wykonywana jest ewaluacja wytrenowanego modelu, w celu ustalenia ostatecznej dokładności klasyfikacji na zbiorze testowym.

\subsubsection{Wydajność}

Stworzony na potrzeby projektu skrypt \verb+capture.py+ pozwala na włączenie trybu \emph{debug}, dzięki któremu wyniki wydajnościowe każdego klasyfikatora są wypisywane na ekran. Podawane są~wartości takie jak:
\begin{itemize}
    \item minimalny czas klasyfikacji od początku działania skryptu,
    \item maksymalny czas klasyfikacji od początku działania skryptu,
    \item średni czas klasyfikacji od początku działania skryptu.
\end{itemize}
Zdecydowano się nie liczyć mediany, ponieważ wymagałoby to zapamiętania wszystkich czasów klasyfikacji, co~wpłynęłoby negatywnie na~zużycie pamięci.

\subsubsection{Próba czasowa}

W~tym teście zbadano zachowanie wszystkich trzech klasyfikatorów jednocześnie w~tym samym scenariuszu, obejmującym rozpoznawanie kształtów w~czasie rzeczywistym na~strumieniu wideo. Wykorzystano w~tym celu opisywany wcześniej skrypt \verb+capture.py+, przy pomocy którego ustawiono na~rozpoznawanie konkretnego kształtu i~uruchomiono próbę czasową. Zadaniem jest poprawna klasyfikacja pokazywanego kształtu przez jak najdłuższy okres czasu, przy czym dopuszcza~się pomyłkę przez nie~dłużej niż 8~klatek z~rzędu. Zwrócenie błędnego wyniku przez dłużej niż~ustalony limit powoduje zakończenie pomiaru czasu dla~danego klasyfikatora. Dodatkowo podczas trwania próby dla każdego klasyfikatora zliczano klatki, na których doszło do poprawnej klasyfikacji w tym samym okresie czasu.

\subsection{Uzyskane wyniki}

W poniższym podrozdziale opisano wyniki uzyskane przy pomocy opisanych powyżej testów.

\subsubsection{Dokładność}

W zbiorze \cite{shapes} znajduje się 14970 obrazów --- 3720 kół, 3765 kwadratów, 3765 gwiazd i 3720 trójkątów. Dla każdego z klasyfikatorów wyznaczono dokładność uruchamiając proces klasyfikacji na każdym z obrazów przy pomocy skryptu \verb+image_test.py+ i zliczając stosunek poprawnych dopasowań do liczby wszystkich prób. Wyniki wyglądają następująco:
\begin{itemize}
    \item Klasyfikator geometryczny zakwalifikował poprawnie 14911 kształtów, co daje dokładność na poziomie 0.9961 w przybliżeniu.
    W~tym przypadku najgorzej wypadły trójkąty --- były tam aż~153 pomyłki.
    \item Klasyfikator korzystający z sieci neuronowej klasyfikującej wektory zidentyfikował poprawnie 14813 kształtów, co daje dokładność na~poziomie 0.9895. Najwięcej błędów zostało popełnionych w~przypadku klasyfikacji gwiazd (46).
    \item Klasyfikator korzystający z konwolucyjnej sieci neuronowej rozpoznał poprawnie 14915 kształtów, co daje dokładność na poziomie 0.9963 w przybliżeniu. Podobnie jak w~przypadku klasyfikatora geometrycznego, najgorzej wypadła klasyfikacja trójkątów (53 pomyłki).
\end{itemize}

Warto zauważyć, że poza siedmioma przypadkami błędnej identyfikacji trójkątów jako kwadraty i~gwiazdy przez sieć konwolucyjną, nie wystąpiły żadne błędy pierwszego typu (ang. \emph{false positive errors}). Wszystkie popełnione błędy dotyczyły nierozpoznania znanego kształtu.

Jak już wspomniano wcześniej, dokładność była także wypisywana na ekran w trakcie treningu sieci neuronowych. Wartość wyznaczona podczas ewaluacji wytrenowanego modelu w~przypadku sieci klasyfikującej wektory to 0.9980, natomiast dla sieci konwolucyjnej zwrócona wartość była 1.0 (wyniosła tyle już po siedemnastej z 25 epok).

Dodatkowo przeprowadzono eksperyment mający na celu sprawdzić wpływ wielkości zbioru treningowego na dokładność klasyfikacji przy użyciu klasyfikatorów opartych o~sieci neuronowe. Przetestowano wielkości: $[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]$, gdzie każdy z ułamków oznacza jak duża część obrazów ze zbioru \cite{shapes} zostanie użyta podczas treningu. Przykładowo, dla wielkości 0.8 będzie to 80\% obrazów.
Wyniki eksperymentu przedstawia wykres~\ref{fig:test-train-proportions}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{res/img/test-train-proportions.pdf}
    \caption{Wykres przedstawiający wpływ stosunku liczności zbioru treningowego i~testowego na~dokładność klasyfikacji}
    \label{fig:test-train-proportions}
\end{figure}

Łatwo zauważyć, że od wielkości zbioru treningowego wynoszącej około 150 zdjęć, wyniki są bardzo dobre i wszystkie na poziomie dokładności zbliżonym do 1.

\subsubsection{Wydajność}

Wydajność każdej z metod klasyfikacji zmierzono na dwa sposoby. Pierwszym źródłem wyników był wykorzystany do badania dokładności skrypt \verb+image_test.py+, w którym zmierzono upływ czasu klasyfikacji wszystkich 14970 obrazów łącznie z ich obróbką przez ekstraktor. Otrzymane wyniki są następujące:
\begin{itemize}
    \item Klasyfikator geometryczny skończył klasyfikację obrazów w 28.66s, co daje w przybliżeniu średnio 0.0019s na obróbkę i klasyfikację każdego kształtu.
    \item Klasyfikator korzystający z sieci neuronowej klasyfikującej wektory skończył klasyfikację obrazów w 43.67s, co daje w przybliżeniu średnio 0.0029s na obróbkę i klasyfikację każdego kształtu.
    \item Klasyfikator korzystający z konwolucyjnej sieci neuronowej skończył klasyfikację obrazów w 48.53s, co daje w przybliżeniu średnio 0.0032s na obróbkę i klasyfikację każdego kształtu.
\end{itemize}

Drugim źródłem wyników był działający w trybie \emph{debug} skrypt \verb+capture.py+. Dla każdego z klasyfikatorów otrzymano następujące wyniki klasyfikacji pojedynczego kształtu (bez wliczonej obróbki wstępnej):
\begin{itemize}
    \item Klasyfikator geometryczny:
    \begin{itemize}
        \item najkrótszy czas klasyfikacji wyniósł 0.000018s,
        \item najdłuższy czas klasyfikacji wyniósł 0.001961s,
        \item średni czas klasyfikacji wyniósł 0.000086s.
    \end{itemize}
    \item Klasyfikator korzystający z sieci neuronowej klasyfikującej wektory:
    \begin{itemize}
        \item najkrótszy czas klasyfikacji wyniósł 0.000981s,
        \item najdłuższy czas klasyfikacji wyniósł 0.022804s,
        \item średni czas klasyfikacji wyniósł 0.001918s.
    \end{itemize}
    \item Klasyfikator korzystający z konwolucyjnej sieci neuronowej:
    \begin{itemize}
        \item najkrótszy czas klasyfikacji wyniósł 0.001086s,
        \item najdłuższy czas klasyfikacji wyniósł 0.035751s,
        \item średni czas klasyfikacji wyniósł 0.002212s.
    \end{itemize}
\end{itemize}

\subsubsection{Próba czasowa}

Testom poddano każdy z kształtów osobno przy dodatkowym zastosowaniu różnych utrudnień, którymi są:
\begin{itemize}
    \item translacja (przesuwanie) kształtu wzdłuż~płaszczyzny kamery,
    \item obrót kształtu,
    \item przechylenie kształtu względem~płaszczyzny kamery,
    \item przybliżanie i~oddalanie kształtu.
\end{itemize}

Zmierzono zarówno czas, po~którym klasyfikator poczynił pierwszą pomyłkę (patrz: tabela~\ref{tab:time-trials}), jak i~liczbę klatek, na~których dany klasyfikator rozpoznał pokazywany kształt (patrz: tabela~\ref{tab:frame-count}).

Kolumny oznaczone jako \emph{geometric}, \emph{network (vec)} oraz \emph{network (conv)} odpowiadają odpowiednio klasyfikatorom: geometrycznemu, opartemu na sieci neuronowej klasyfikującej wektory oraz sieci konwolucyjnej.

\begin{table}[H]
    \begin{tabularx}{\textwidth}{|c|c|Yr|Yr|Yr|Y|}
        \hline
        \textbf{Test} & \textbf{Typ} & \multicolumn{2}{c|}{\textbf{geometric}} & \multicolumn{2}{c|}{\textbf{network (vec)}} & \multicolumn{2}{c|}{\textbf{network (conv)}} & \textbf{Czas trwania próby} \\
        \hline
        \hline
        \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Translacja}}}
        & $\blacksquare$ & 00:03.123 & \footnotesize{(0.210)} & 00:06.607 & \footnotesize{(0.445)} & 00:03.123 & \footnotesize{(0.210)} & 00:14.842 \\
        \cline{2-9}
        & $\bullet$ & 00:13.728 & \footnotesize{(1.000)} & 00:09.431 & \footnotesize{(0.687)} & 00:13,728 & \footnotesize{(1.000)} & 00:13.728 \\
        \cline{2-9}
        & $\blacktriangle$ & 00:03.457 & \footnotesize{(0.228)} & 00:14.567 & \footnotesize{(0.960)} & 00:02.941 & \footnotesize{(0.194)} & 00:15.175 \\
        \cline{2-9}
        & $\bigstar$ & 00:18.754 & \footnotesize{(1.000)} & 00:18.754 & \footnotesize{(1.000)} & 00:18.754 & \footnotesize{(1.000)} & 00:18.754 \\
        \hline
        \hline
        \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Obrót}}}
        & $\blacksquare$ & 00:05.132 & \footnotesize{(0.278)} & 00:18.430 & \footnotesize{(1.000)} & 00:18.430 & \footnotesize{(1.000)} & 00:18.430 \\
        \cline{2-9}
        & $\bullet$ & 00:14.784 & \footnotesize{(0.992)} & 00:14.691 & \footnotesize{(0.985)} & 00:14.784 & \footnotesize{(0.992)} & 00:14.909 \\
        \cline{2-9}
        & $\blacktriangle$ & 00:13.433 & \footnotesize{(0.665)} & 00:20.215 & \footnotesize{(1.000)} & 00:13.699 & \footnotesize{(0.678)} & 00:20.215 \\
        \cline{2-9}
        & $\bigstar$ & 00:16.845 & \footnotesize{(1.000)} & 00:16.845 & \footnotesize{(1.000)} & 00:16.845 & \footnotesize{(1.000)} & 00:16.845 \\
        \hline
        \hline
        \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Przechylenie}}}
        & $\blacksquare$ & 00:02.798 & \footnotesize{(0.203)} & 00:02.721 & \footnotesize{(0.198)} & 00:02.721 & \footnotesize{(0.198)} & 00:13.767 \\
        \cline{2-9}
        & $\bullet$ & 00:02.316 & \footnotesize{(0.151)} & 00:02.208 & \footnotesize{(0.144)} & 00:03.505 & \footnotesize{(0.228)} & 00:15.364 \\
        \cline{2-9}
        & $\blacktriangle$ & 00:03.185 & \footnotesize{(0.224)} & 00:14.217 & \footnotesize{(1.000)} & 00:11.514 & \footnotesize{(0.810)} & 00:14.217 \\
        \cline{2-9}
        & $\bigstar$ & 00:10.690 & \footnotesize{(0.556)} & 00:08.790 & \footnotesize{(0.457)} & 00:08.142 & \footnotesize{(0.423)} & 00:19.236 \\
        \hline
        \hline
        \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Przybliżenie}}}
        & $\blacksquare$ & 00:15.519 & \footnotesize{(0.984)} & 00:15.769 & \footnotesize{(1.000)} & 00:15.769 & \footnotesize{(1.000)} & 00:15.769 \\
        \cline{2-9}
        & $\bullet$ & 00:17.920 & \footnotesize{(1.000)} & 00:17.920 & \footnotesize{(1.000)} & 00:17.920 & \footnotesize{(1.000)} & 00:17.920 \\
        \cline{2-9}
        & $\blacktriangle$ & 00:02.378 & \footnotesize{(0.152)} & 00:05.690 & \footnotesize{(0.364)} & 00:15.643 & \footnotesize{(1.000)} & 00:15.643 \\
        \cline{2-9}
        & $\bigstar$ & 00:14.770 & \footnotesize{(1.000)} & 00:14.770 & \footnotesize{(1.000)} & 00:14.770 & \footnotesize{(1.000)} & 00:14.770 \\
        \hline
    \end{tabularx}
    \caption{
        Tabela ukazująca czas, który upłynął od~początku danego testu do~pierwszej pomyłki dla~każdego klasyfikatora.
        Pomyłką uznajemy błędną klasyfikację kształtu przez~dłużej niż~4~kolejne ramki obrazu.
        W~nawiasach stosunek do~całkowitej długości danej próby.}
    \label{tab:time-trials}
\end{table}

\newcolumntype{R}{>{\raggedleft\arraybackslash}X}
\begin{table}[H]
    \begin{tabularx}{\textwidth}{|c|c|Rr|Rr|Rr|Y|}
        \hline
        \textbf{Test} & \textbf{Typ} & \multicolumn{2}{c|}{\textbf{geometric}} & \multicolumn{2}{c|}{\textbf{network (vec)}} & \multicolumn{2}{c|}{\textbf{network (conv)}} & \textbf{Całk. liczba klatek} \\
        \hline
        \hline
        \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Translacja}}}
        & $\blacksquare$ & 159 & \footnotesize{(0.710)} & 197 & \footnotesize{(0.879)} & 191 & \footnotesize{(0.853)} & 224 \\
        \cline{2-9}
        & $\bullet$ & 146 & \footnotesize{(0.954)} & 126 & \footnotesize{(0.824)} & 141 & \footnotesize{(0.922)} & 153 \\
        \cline{2-9}
        & $\blacktriangle$ & 159 & \footnotesize{(0.694)} & 202 & \footnotesize{(0.882)} & 151 & \footnotesize{(0.659)} & 229 \\
        \cline{2-9}
        & $\bigstar$ & 277 & \footnotesize{(0.979)} & 280 & \footnotesize{(0.989)} & 281 & \footnotesize{(0.993)} & 283 \\
        \hline
        \hline
        \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Obrót}}}
        & $\blacksquare$ & 256 & \footnotesize{(0.921)} & 271 & \footnotesize{(0.975)} & 275 & \footnotesize{(0.989)} & 278 \\
        \cline{2-9}
        & $\bullet$ & 211 & \footnotesize{(0.938)} & 215 & \footnotesize{(0.956)} & 219 & \footnotesize{(0.973)} & 225 \\
        \cline{2-9}
        & $\blacktriangle$ & 268 & \footnotesize{(0.879)} & 290 & \footnotesize{(0.951)} & 286 & \footnotesize{(0.938)} & 305 \\
        \cline{2-9}
        & $\bigstar$ & 254 & \footnotesize{(1.000)} & 231 & \footnotesize{(0.909)} & 248 & \footnotesize{(0.976)} & 254 \\
        \hline
        \hline
        \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Przechylenie}}}
        & $\blacksquare$ & 78 & \footnotesize{(0.375)} & 91 & \footnotesize{(0.438)} & 94 & \footnotesize{(0.452)} & 208 \\
        \cline{2-9}
        & $\bullet$ & 94 & \footnotesize{(0.448)} & 84 & \footnotesize{(0.400)} & 101 & \footnotesize{(0.481)} & 210 \\
        \cline{2-9}
        & $\blacktriangle$ & 105 & \footnotesize{(0.488)} & 134 & \footnotesize{(0.623)} & 115 & \footnotesize{(0.535)} & 215 \\
        \cline{2-9}
        & $\bigstar$ & 209 & \footnotesize{(0.804)} & 171 & \footnotesize{(0.658)} & 205 & \footnotesize{(0.788)} & 260 \\
        \hline
        \hline
        \multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Przybliżenie}}}
        & $\blacksquare$ & 205 & \footnotesize{(0.861)} & 238 & \footnotesize{(1.000)} & 234 & \footnotesize{(0.983)} & 234 \\
        \cline{2-9}
        & $\bullet$ & 239 & \footnotesize{(0.992)} & 240 & \footnotesize{(0.996)} & 241 & \footnotesize{(1.000)} & 241 \\
        \cline{2-9}
        & $\blacktriangle$ & 134 & \footnotesize{(0.568)} & 217 & \footnotesize{(0.919)} & 236 & \footnotesize{(1.000)} & 236 \\
        \cline{2-9}
        & $\bigstar$ & 223 & \footnotesize{(1.000)} & 220 & \footnotesize{(0.987)} & 223 & \footnotesize{(1.000)} & 223 \\
        \hline
    \end{tabularx}
    \caption{
        Tabela ukazująca liczbę klatek, przez~którą każdy klasyfikator rozpoznał pokazywany kształt w~danym teście.
        W~nawiasach stosunek do~całkowitej liczby zarejestrowanych klatek.}
    \label{tab:frame-count}
\end{table}

Wyniki względne z~tabel~\ref{tab:time-trials} i~\ref{tab:frame-count} zostały uśrednione w~tabeli~\ref{tab:average-ratio}.

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{|l|Y|Y|}
        \hline
        \textbf{Klasyfikator} & \textbf{Czas do~pierwszej pomyłki} & \textbf{Odsetek rozpoznanych klatek} \\
        \hline
        geometric & 0.603 & 0.788 \\
        \hline
        network (vec) & 0.765 & 0.837 \\
        \hline
        network (conv) & 0.733 & 0.846 \\
        \hline
    \end{tabularx}
    \caption{Uśrednione wyniki względne z~prób przedstawionych w~tabeli~\ref{tab:time-trials} i~\ref{tab:frame-count}}
    \label{tab:average-ratio}
\end{table}

Wyniki testu empirycznego wskazują, że~klasyfikator geometryczny dość znacząco odstaje od~pozostałych, zarówno pod~względem czasu do~pierwszej pomyłki, jak~i~liczbie klatek, na~których kształt był rozpoznany.
Klasyfikatory używające modeli sieci neuronowych mają zbliżone wyniki --- sieć konwolucyjna wydaje~się rozpoznawać kształty trochę~lepiej kosztem stabilności (większy odsetek rozpoznanych klatek, lecz krótszy czas do~błędu).

\section{Podsumowanie}

Przeprowadzone eksperymenty pokazują, że~wszystkie zastosowane podejścia dość dobrze radzą sobie z~problemem rozpoznawania prostych kształtów.
Zauważalne są jednak między nimi różnice w~dziedzinie wydajności i~efektywności.
Mimo tego do klasyfikacji w~każdym przypadku dochodzi na tyle szybko, że przeprowadzanie jej dla wszystkich trzech klasyfikatorów jednocześnie w czasie rzeczywistym nie stanowi problemu.

Klasyfikator oparty na~konturach wykazuje w~eksperymentach najkrótszy czas działania, lecz często działa dość niestabilnie, co~wykazała próba czasowa.
Z~kolei sieci neuronowe mimo konieczności treningu na~wcześniej przygotowanym zbiorze oraz dłuższego czasu klasyfikacji, nadal mogą być używane do~rozpoznawania w~czasie rzeczywistym, i~działają mniej chaotycznie, niż podejście typowo geometryczne.

\subsection{Możliwości dalszych badań}

Istnieje kilka potencjalnych zagadnień, stanowiących naturalną kontynuację opracowanego projektu:

\begin{itemize}
    \item Naturalnym rozszerzeniem istniejącego rozwiązania byłoby dodanie większej liczby rodzajów rozpoznawanych kształtów.
    Koszt takiego rozszerzenia różniłby~się znacząco pomiędzy klasyfikatorami --- podczas gdy rozszerzenie klasyfikatora geometrycznego byłoby stosunkowo bezproblemowe, dla~pozostałych dwóch należałoby przygotować zbiór treningowy oraz~ponownie wytrenować model sieci.
    \item Interesującym aspektem analizy stworzonych rozwiązań byłaby również ocena ich podatności na~błędy pierwszego rodzaju (ang. \emph{false positive}).
    Znane są rozwiązania używające np.~sieci adwersaryjnych (ang. \emph{adversarial network}) w~celu wygenerowania obrazów powodujących błędne działanie klasyfikatorów opartych na~sieciach neuronowych.
    \item Pewną wadą modeli dopasowanych w~ramach projektów jest nieuwzględnienie w~zbiorze treningowych obiektów niepasujących do~żadnej z~kategorii kształtów.
    Wobec tego pomysłem wartym rozważenia byłoby dodanie dodatkowej zbiorczej klasy na~wszystkie pozostałe kształty niepasujące do~ustalonych archetypów.
\end{itemize}

\begin{thebibliography}{99}

    \bibitem{bishop1995}
        C.M. Bishop:
        \emph{Neural Networks for~Pattern Recognition}.
        Oxford University Press:
        Nowy Jork,
        1995.

    \bibitem{keras}
        F. Chollet, Keras Team:
        Keras -- Deep Learning for humans. \\
        Oficjalna strona: \url{https://keras.io}
        [Dostęp 17~marca 2018]

    \bibitem{h5py}
        A. Collette,
        HDF5 for Python. \\
        Oficjalna strona: \url{https://www.h5py.org/}
        [Dostęp 27~maja 2018]
        
    \bibitem{douglas1973}
        D.H. Douglas,
        T.K. Peucker,
        ,,Algorithms for the Reduction of~the~Number of~Points Required to~Represent a~Digitized Line or its Caricature'',
        \emph{Cartographica: The International Journal for Geographic Information and~Geovisualization},
        tom 10,
        s. 112--122,
        1973.

    \bibitem{opencv}
        Intel Corporation, Willow Garage, Itseez:
        OpenCV -- Open Source Computer Vision. \\
        Oficjalna strona: \url{https://opencv.org}.
        [Dostęp 17~marca 2018]

    \bibitem{matplotlib}
        Matplotlib Development Team:
        Matplotlib. \\
        Oficjalna strona: \url{https://matplotlib.org}.
        [Dostęp 17~marca 2018]

    \bibitem{pandas}
        W. McKinney:
        pandas -- Python Data Analysis Library. \\
        Oficjalna strona: \url{https://pandas.pydata.org}.
        [Dostęp 17~marca 2018]

    \bibitem{shapes}
        S. Meschke:
        Four Shapes dataset. \\
        Dostępny: \url{https://www.kaggle.com/smeschke/four-shapes}.
        [Dostęp 17~marca 2018]

    \bibitem{murty2015}
        M.N. Murty,
        V.S. Devi:
        \emph{Introduction to~Pattern Recognition and~Machine Learning}.
        World Scientific Publishing:
        Singapur,
        2015.

    \bibitem{numpy}
        T. Oliphant:
        NumPy. \\
        Oficjalna strona: \url{http://www.numpy.org}.
        [Dostęp 17~marca 2018]
        
    \bibitem{srivastava2014}
        N. Srivastava,
        G. Hinton,
        A. Krizhevsky,
        I. Sutskever,
        R. Salakhutdinov,
        ,,Dropout: A Simple Way to Prevent Neural Networks from Overfitting'',
        \emph{Journal of Machine Learning Research},
        tom 15,
        s.~1929--1958,
        2014.

    \bibitem{suzuki1985}
        S. Suzuki,
        K. Abe,
        ,,Topological structural analysis of~digitized binary images''
        \emph{Computer Vision, Graphics and~Image Processing},
        tom 30,
        s.~32--66,
        1985.

    \bibitem{tensorflow}
        TensorFlow Team:
        TensorFlow -- An open source machine learning framework for everyone. \\
        Oficjalna strona: \url{https://www.tensorflow.org/}
        [Dostęp 27~maja 2018]

\end{thebibliography}

\end{document}